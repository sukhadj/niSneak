{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import tqdm\n",
    "from hyperopt import tpe,hp,Trials\n",
    "from hyperopt.fmin import fmin\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b796d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_pool = []\n",
    "for filename in os.listdir('./data_use/'):\n",
    "    repo_pool.append(os.path.join(filename))\n",
    "    \n",
    "base_df = pd.read_csv('./data_use/' + repo_pool[0])\n",
    "base_df = base_df.drop(columns=['dates'])\n",
    "print(base_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_pool = []\n",
    "for filename in os.listdir('./data_use/'):\n",
    "    repo_pool.append(os.path.join(filename))\n",
    "    \n",
    "base_df = pd.read_csv('./data_use/' + repo_pool[0])\n",
    "base_df = base_df.drop(columns=['dates'])\n",
    "target_col = 'monthly_closed_issues_12mo'\n",
    "real_df_cols = [col for col in base_df.columns]\n",
    "real_df_cols.append(target_col)\n",
    "lines = []\n",
    "projects = []\n",
    "train_lines = []\n",
    "test_lines = []\n",
    "p_names = os.listdir('./data_use/')\n",
    "#print(repo_pool)\n",
    "for index, repo in enumerate(repo_pool):\n",
    "    print(repo)\n",
    "    project = []\n",
    "    p_train_lines = []\n",
    "    p_test_lines = []\n",
    "    df = pd.read_csv('./data_use/' + repo)\n",
    "    df = df.drop(columns=['dates'])\n",
    "\n",
    "    matrix = df.to_numpy()\n",
    "    for i in range(matrix.shape[0]-12):\n",
    "        row = []\n",
    "        for j in range(matrix.shape[1]):\n",
    "            row.append(matrix[i][j])\n",
    "        row.append(matrix[i+12][8])\n",
    "        lines.append(row)\n",
    "    for i, line in enumerate(lines):\n",
    "        if i < len(lines)*0.7:\n",
    "            train_lines.append(line)\n",
    "            p_train_lines.append(line)\n",
    "        else:\n",
    "            test_lines.append(line)\n",
    "            p_test_lines.append(line)\n",
    "    print('./datasets/health_'+p_names[index][:-4])\n",
    "#     p_df = pd.DataFrame(p_train_lines, columns = real_df_cols)\n",
    "#     p_df.to_csv('./datasets/'+target_col+'/health_'+p_names[index][:-4]+'_train.csv', index=False)\n",
    "#     p_df_t = pd.DataFrame(p_test_lines, columns = real_df_cols)\n",
    "#     p_df.to_csv('./datasets/'+target_col+'/health_'+p_names[index][:-4]+'_test.csv', index=False)\n",
    "    project.append(p_train_lines)\n",
    "    project.append(p_test_lines)\n",
    "    projects.append(project)\n",
    "    lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_lines, columns = real_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26492220",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_lines, columns = real_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1341433",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "\n",
    "def objective(params):\n",
    "    est=int(params['n_estimators'])\n",
    "    cr = params['criterion']\n",
    "    md=int(params['max_depth'])\n",
    "    msl=int(params['min_samples_leaf'])\n",
    "    mid=int(params['min_impurity_decrease'])\n",
    "    model=RandomForestRegressor(n_estimators=est,criterion=cr,max_depth=md,min_samples_leaf=msl,min_impurity_decrease=mid)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    mmre_l = []\n",
    "    mmreg_l = []\n",
    "    pred40 = 0\n",
    "    for y_t, y_p in zip(y_test, y_pred):\n",
    "        num = np.abs(y_p - y_t)\n",
    "        den = np.abs(y_t)\n",
    "        mre = 0\n",
    "        mreg = 0\n",
    "        if den == 0:\n",
    "            if num != 0:\n",
    "                den+=1\n",
    "                num+=1\n",
    "                mre = num/den\n",
    "                mmre_l.append(mre)\n",
    "            else:\n",
    "                mmre_l.append(mre)\n",
    "        else:\n",
    "            mre = num/den\n",
    "            mmre_l.append(mre)\n",
    "        if mre <= 0.4:\n",
    "            pred40+=1\n",
    "        \n",
    "    MRE = np.median(np.array(mmre_l))\n",
    "    MREG = np.median(np.array(mmreg_l))\n",
    "    limit = int(len(y_test)*.7)\n",
    "    sa_num = mean_absolute_error(y_test,  y_pred)\n",
    "    y_predg = np.nan_to_num([(np.median(y_pred[:i])) for i in range(len(y_pred))])\n",
    "    se_den = mean_absolute_error(y_test, y_predg)\n",
    "    if se_den == 0:\n",
    "        if sa_num == 0:\n",
    "            acc = 1\n",
    "        acc = 1 - ( (sa_num + 1) / (se_den+1) )\n",
    "    else:\n",
    "        acc = 1 - ( sa_num / se_den )\n",
    "    global mre_list\n",
    "    mre_list.append(MRE)\n",
    "    global pred40_list\n",
    "    pred40_list.append(pred40/100)\n",
    "    global acc_list\n",
    "    acc_list.append(acc)\n",
    "    n=3\n",
    "    val = -math.e**(1 * (MRE - np.median(np.array(mre_list))) / n) \n",
    "    val -= - math.e**(-1 * ((pred40/100) - np.median(np.array(pred40_list))) / n)\n",
    "    val -= - math.e**(-1 * (acc - np.median(np.array(acc_list))) / n)\n",
    "    return MRE\n",
    "\n",
    "def optimize(trial):\n",
    "    params={'n_estimators':hp.uniform('n_estimators',10,200),\n",
    "           'max_depth':hp.uniform('max_depth',5,20),\n",
    "            'criterion':hp.choice('criterion', ['squared_error', 'absolute_error']),\n",
    "           'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "           'min_impurity_decrease':hp.uniform('min_impurity_decrease',0,10)}\n",
    "    best=fmin(fn=objective,space=params,algo=tpe.suggest,trials=trial,max_evals=3500,rstate=np.random.default_rng(seed))\n",
    "    return best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd512d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClf(params):\n",
    "    if len(params) != 5:\n",
    "        print(\"Missing params\")\n",
    "        return None\n",
    "    else:\n",
    "        criterion = 'squared_error'\n",
    "        criterion_enum = params['criterion']\n",
    "        if criterion_enum == 0:\n",
    "            criterion = 'squared_error'\n",
    "        elif criterion_enum == 1:\n",
    "            criterion = 'absolute_error'\n",
    "        return RandomForestRegressor(n_estimators=int(params['n_estimators']), criterion=criterion, min_samples_leaf=int(params['min_samples_leaf']), min_impurity_decrease=params['min_impurity_decrease'], max_depth=int(params['max_depth']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda05401",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evals = []\n",
    "model_data_l = []\n",
    "index=0\n",
    "for project in projects:\n",
    "    eval_row , data_row = [], []\n",
    "    start_time = time.time()\n",
    "    global mre_list\n",
    "    mre_list = [0]\n",
    "    global pred40_list\n",
    "    pred40_list = [1]\n",
    "    global acc_list\n",
    "    acc_list = [1]\n",
    "    # pbar.set_description('Running %s' %p_names[index])\n",
    "    metrics_data = []\n",
    "    train_df = pd.DataFrame(project[0], columns = real_df_cols)\n",
    "    test_df = pd.DataFrame(project[1], columns = real_df_cols)\n",
    "    X_train = train_df.iloc[:, 1:-1]\n",
    "    X_test = test_df.iloc[:, 1:-1]\n",
    "    y_train = train_df.iloc[:, -1:].values.flatten().tolist()\n",
    "    y_test = np.array(test_df.iloc[:, -1:].values.flatten().tolist())\n",
    "    mre_past = [0]\n",
    "    pred40_past = [1]\n",
    "    acc_past = [1]\n",
    "    trial=Trials()\n",
    "    params=optimize(trial)\n",
    "    clf = generateClf(params)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    mmre_l = []\n",
    "    mmreg_l = []\n",
    "    pred40 = 0\n",
    "    i = 0\n",
    "    for y_t, y_p in zip(y_test, y_pred):\n",
    "        num = np.abs(y_p - y_t)\n",
    "        den = np.abs(y_t)\n",
    "        mre = 0\n",
    "        mreg = 0\n",
    "        if den == 0:\n",
    "            if num != 0:\n",
    "                den+=1\n",
    "                num+=1\n",
    "                mre = num/den\n",
    "                mmre_l.append(mre)\n",
    "            else:\n",
    "                mmre_l.append(mre)\n",
    "        else:\n",
    "            mre = num/den\n",
    "            mmre_l.append(mre)\n",
    "        if mre <= 0.4:\n",
    "            pred40+=1\n",
    "        i+=1\n",
    "    MRE = np.median(np.array(mmre_l))\n",
    "    MREG = np.median(np.array(mmreg_l))\n",
    "    # print(\"MRES=\",np.array(mmre_l))\n",
    "    data_row.append(p_names[index])\n",
    "    data_row.append('hyperopt')\n",
    "    data_row.append(5000)\n",
    "    criterion = 'poisson'\n",
    "    criterion_enum = params['criterion']\n",
    "    if criterion_enum == 0:\n",
    "        criterion = 'squared_error'\n",
    "    elif criterion_enum == 1:\n",
    "        criterion = 'absolute_error'\n",
    "    n_estimators=int(params['n_estimators'])\n",
    "    min_samples_leaf=int(params['min_samples_leaf'])\n",
    "    min_impurity_decrease=params['min_impurity_decrease']\n",
    "    max_depth=int(params['max_depth'])\n",
    "    data_row.append(n_estimators)\n",
    "    data_row.append(criterion)\n",
    "    data_row.append(min_samples_leaf)\n",
    "    data_row.append(min_impurity_decrease)\n",
    "    data_row.append(max_depth)\n",
    "    \n",
    "    # import pdb;pdb.set_trace()\n",
    "    eval_row.append(round(MRE * 100, 2))\n",
    "    limit = int(len(y_test)*.7)\n",
    "    sa_num = mean_absolute_error(y_test,  y_pred)\n",
    "    y_predg = np.nan_to_num([(np.median(y_pred[:i])) for i in range(len(y_pred))])\n",
    "    se_den = mean_absolute_error(y_test, y_predg)\n",
    "    if se_den == 0:\n",
    "        if sa_num == 0:\n",
    "            acc = 1\n",
    "        acc = 1 - ( (sa_num + 1) / (se_den+1) )\n",
    "    else:\n",
    "        acc = 1 - ( sa_num / se_den )\n",
    "    eval_row.append(pred40)\n",
    "    eval_row.append(round(acc*100, 2))\n",
    "    pred40 = pred40 / len(y_pred) * 100\n",
    "    data_row.append(time.time() - start_time)\n",
    "    evals.append(eval_row)\n",
    "    model_data_l.append(data_row)\n",
    "   \n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_data = pd.DataFrame(evals, columns = ['MdMRE', 'PRED40', 'SA']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.DataFrame(model_data_l, columns = ['ds', 'Optimizer', 'Models built','N_estimators', 'Criterion', 'Min_samples_leaf','Min_impurity_decrease', 'Max_depth', 'Time']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add01a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_full = pd.concat([model_data, evals_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_full = eval_data_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b689fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_eval_data=(evals_data-evals_data.min())/(evals_data.max()-evals_data.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96686f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_eval_data.columns = ['N_MdMRE', 'N_PRED40', 'N_SA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_full = pd.concat([normalized_eval_data, evals_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_full = pd.concat([eval_data_full, model_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428361e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_full.to_csv('./evals/'+target_col+'/hyperopt_all_data_full_multi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c94a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
